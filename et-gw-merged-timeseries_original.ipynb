{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d425741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyhdf.SD import SD, SDC\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import from_origin\n",
    "from pyproj import CRS\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7afe5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT INPUTS BASED ON SITE OF INTEREST\n",
    "\n",
    "# Single site to process\n",
    "SITE_NAME = \"MexicoAguascaliente\"\n",
    "\n",
    "# Year range\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2022\n",
    "\n",
    "# Paths\n",
    "sites_csv = \"/capstone/aridgw/data/2025_09_21_annual_median_groundwater_levels_16sites_tile_id.csv\"\n",
    "modis_data_dir = \"/capstone/aridgw/data/modis_data/\"\n",
    "output_csv = \"/capstone/aridgw/data/et_timeseries_aguascaliente_test.csv\"\n",
    "merged_output_csv = \"/capstone/aridgw/data/et_gw_merged_aguascaliente_test.csv\"  # Output for merged ET and GW data\n",
    "# Buffer radius in meters\n",
    "BUFFER_RADIUS = 1000  # 1 km\n",
    "\n",
    "# MODIS constants\n",
    "TILE_SIZE = 1111950.0\n",
    "X_MIN = -20015109.354\n",
    "Y_MAX = 10007554.677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6cca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real MODIS filename example \n",
    "# MOD16A3GF.A2000001.h00v08.061.2020264071747.hdf\n",
    "# MOD16A3GF MODIS data naming convention \n",
    "# 2000 Year \n",
    "# Day of year 001\n",
    "# h00v08 Tile h=0, v=8\n",
    "# 061 = Collection number\n",
    "# 2020264071747 = Production date\n",
    "# {} Ensures there is a match for the specified number of digits\n",
    "# ({}) Captures name as a group after ensuring there is a match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb162a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used in processing\n",
    "\n",
    "def parse_modis_filename(filename):\n",
    "    \"\"\"Extract year, tile, h, v from MODIS filename\"\"\"\n",
    "    # Naming convention first \n",
    "    pattern = r'MOD16A3GF\\.A(\\d{4})\\d{3}\\.h(\\d{2})v(\\d{2})\\.\\d{3}\\.\\d+\\.hdf' # Defines regex pattern for MODIS filenames containing time and tile info\n",
    "    match = re.search(pattern, filename) # Looks through modis_data_dir for files that match the pattern\n",
    "    \n",
    "    if match:\n",
    "        return { # Returns a dictionary with extracted time and tile info\n",
    "            'year': int(match.group(1)),\n",
    "            'tile': f\"h{match.group(2)}v{match.group(3)}\",\n",
    "            'h': int(match.group(2)),\n",
    "            'v': int(match.group(3))\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def create_circle_buffer(center_lat, center_lon, radius_meters, target_crs):\n",
    "    \"\"\"Create circular buffer around site point\n",
    "        - Input lat/lon in degrees\n",
    "        - radius in meters\n",
    "        - target_crs: pyproj CRS object for target projection (MODIS Sinusoidal)\n",
    "    \"\"\"\n",
    "    point = gpd.GeoSeries([Point(center_lon, center_lat)], crs=\"EPSG:4326\") # CRS is EPSG:4326 by default since lat/lon are used\n",
    "    point_projected = point.to_crs(epsg=3857) # Project to Web Mercator for accurate buffering in meters\n",
    "    circle = point_projected.buffer(radius_meters) # Create buffer in meters\n",
    "    circle_target = circle.to_crs(target_crs) # Convert to target CRS (MODIS Sinusoidal)\n",
    "    return circle_target\n",
    "\n",
    "def extract_et_from_buffer(hdf_file, circle_geom, h, v):\n",
    "    \"\"\"Extract mean ET from buffer\n",
    "    - Inputs:\n",
    "        - hdf_file: path to MODIS HDF file\n",
    "        - circle_geom: output geometry of create_circle_buffer function in MODIS CRS\n",
    "        - h, v: tile indices\n",
    "    - Returns:\n",
    "        - mean ET value within buffer (float, mm/yr), or np.nan if no data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open HDF\n",
    "        hdf = SD(hdf_file, SDC.READ)\n",
    "        et_dataset = hdf.select('ET_500m')\n",
    "        scale_factor = et_dataset.scale_factor\n",
    "        fill_value = et_dataset.attributes()['_FillValue'] # Fill values should have been identified, they will turn into NaN\n",
    "        \n",
    "        # Read and clean data\n",
    "        et_data_raw = et_dataset[:].astype(float) # Turn into float for NaN handling\n",
    "        et_data_raw[et_data_raw == fill_value] = np.nan # Set fill values to NaN\n",
    "        et_data_raw[et_data_raw > 65500] = np.nan # Additional cleaning for unrealistic values\n",
    "        et_data = et_data_raw * scale_factor # Scale to (mm/yr) units using scaling factor\n",
    "        \n",
    "        # Setup geotransform\n",
    "        PIXELS = et_data.shape[0] # Number of pixels in one dimension (assuming square)\n",
    "        RES = TILE_SIZE / PIXELS # Calculate resolution, how many meters per pixel\n",
    "        x_ul = X_MIN + h * TILE_SIZE # Upper-left x coordinate\n",
    "        y_ul = Y_MAX - v * TILE_SIZE # Upper-left y coordinate\n",
    "        transform = from_origin(x_ul, y_ul, RES, RES) # Create transformation\n",
    "        modis_crs = CRS.from_proj4(\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\") # MODIS Sinusoidal CRS\n",
    "        \n",
    "        # Create profile and clip\n",
    "        profile = {\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": et_data.shape[0], # Pixels in y direction\n",
    "            \"width\": et_data.shape[1], # Pixels in x direction\n",
    "            \"count\": 1, # of bands\n",
    "            \"dtype\": \"float32\", # Data type\n",
    "            \"crs\": modis_crs, # CRS info\n",
    "            \"transform\": transform, # Transformation info\n",
    "            \"nodata\": np.nan\n",
    "        }\n",
    "        \n",
    "        with MemoryFile() as memfile: # Use in-memory file for rasterio operations for efficiency\n",
    "            with memfile.open(**profile) as dataset:\n",
    "                dataset.write(et_data.astype(\"float32\"), 1)\n",
    "                clipped, _ = mask(dataset, circle_geom.geometry, crop=True) # Clip to buffer area\n",
    "        \n",
    "        # Calculate mean\n",
    "        clipped_valid = clipped[0][~np.isnan(clipped[0])] # Valid (non-NaN) values only\n",
    "        # Conduct mean zonal statistics\n",
    "        mean_et = clipped_valid.mean() if len(clipped_valid) > 0 else np.nan # Mean ET or NaN if no valid data\n",
    "        \n",
    "        hdf.end()\n",
    "        return mean_et\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bb86f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Extracting ET timeseries for: MexicoAguascaliente\n",
      "Years: 2000-2022\n",
      "======================================================================\n",
      "\n",
      " STEP 1: Loading site information from CSV\n",
      "âœ“ Location: MexicoAguascaliente\n",
      "âœ“ Coordinates: (22.198160, -102.310000)\n",
      "âœ“ MODIS Tile: h08v06\n",
      "\n",
      " STEP 2: Creating 1000m buffer\n",
      "âœ“ Buffer created\n",
      "\n",
      " STEP 3: Finding MODIS files for tile h08v06\n",
      "âœ“ Found 7139 total MODIS files\n",
      "âœ“ Filtered to 23 files for h08v06 (2000-2022)\n",
      "\n",
      " STEP 4: Extracting ET values\n",
      "\n",
      "Year     Mean ET (mm/yr)      Status\n",
      "--------------------------------------------------\n",
      "2000     240.62               âœ“\n",
      "2001     269.75               âœ“\n",
      "2002     351.98               âœ“\n",
      "2003     370.08               âœ“\n",
      "2004     392.17               âœ“\n",
      "2005     318.19               âœ“\n",
      "2006     353.13               âœ“\n",
      "2007     380.20               âœ“\n",
      "2008     328.05               âœ“\n",
      "2009     309.63               âœ“\n",
      "2010     348.26               âœ“\n",
      "2011     230.88               âœ“\n",
      "2012     250.20               âœ“\n",
      "2013     342.01               âœ“\n",
      "2014     341.33               âœ“\n",
      "2015     407.38               âœ“\n",
      "2016     336.10               âœ“\n",
      "2017     345.37               âœ“\n",
      "2018     395.41               âœ“\n",
      "2019     340.40               âœ“\n",
      "2020     376.95               âœ“\n",
      "2021     374.45               âœ“\n",
      "2022     329.23               âœ“\n",
      "\n",
      "======================================================================\n",
      "STEP 5: Saving ET results\n",
      "======================================================================\n",
      "âœ“ ET data saved to: /capstone/aridgw/data/et_timeseries_aguascaliente_test.csv\n",
      "\n",
      " ET Statistics:\n",
      "  Years with data: 23 / 23\n",
      "  Mean ET: 336.16 mm/yr\n",
      "  Min ET: 230.88 mm/yr\n",
      "  Max ET: 407.38 mm/yr\n",
      "  Std Dev: 48.59 mm/yr\n",
      "\n",
      "======================================================================\n",
      "STEP 6: Joining ET data with groundwater data\n",
      "======================================================================\n",
      "âœ“ Loaded 20 groundwater records for MexicoAguascaliente\n",
      "\n",
      " Filtering to years 2000-2022...\n",
      "âœ“ Merged dataset has 2 rows\n",
      "  Rows with ET data: 2\n",
      "  Rows without ET data: 0\n",
      "âœ“ Merged data saved to: /capstone/aridgw/data/et_gw_merged_aguascaliente_test.csv\n",
      "\n",
      "ðŸ“‹ Column verification (duplicate columns help verify alignment):\n",
      "     Title Location            location  YEAR   year      Lat  latitude     Lon  longitude tile_id   tile\n",
      "MexicoAguascaliente MexicoAguascaliente  2000 2000.0 22.19816  22.19816 -102.31    -102.31  h08v06 h08v06\n",
      "MexicoAguascaliente MexicoAguascaliente  2001 2001.0 22.19816  22.19816 -102.31    -102.31  h08v06 h08v06\n",
      "\n",
      "======================================================================\n",
      "ET OUTPUT PREVIEW\n",
      "======================================================================\n",
      " year            location  latitude  longitude   tile  mean_ET_mm_yr  buffer_radius_m\n",
      " 2000 MexicoAguascaliente  22.19816    -102.31 h08v06     240.623062             1000\n",
      " 2001 MexicoAguascaliente  22.19816    -102.31 h08v06     269.746155             1000\n",
      " 2002 MexicoAguascaliente  22.19816    -102.31 h08v06     351.976929             1000\n",
      " 2003 MexicoAguascaliente  22.19816    -102.31 h08v06     370.084625             1000\n",
      " 2004 MexicoAguascaliente  22.19816    -102.31 h08v06     392.169220             1000\n",
      " 2005 MexicoAguascaliente  22.19816    -102.31 h08v06     318.192322             1000\n",
      " 2006 MexicoAguascaliente  22.19816    -102.31 h08v06     353.130737             1000\n",
      " 2007 MexicoAguascaliente  22.19816    -102.31 h08v06     380.200012             1000\n",
      " 2008 MexicoAguascaliente  22.19816    -102.31 h08v06     328.053833             1000\n",
      " 2009 MexicoAguascaliente  22.19816    -102.31 h08v06     309.630768             1000\n",
      "\n",
      "======================================================================\n",
      "MERGED OUTPUT PREVIEW\n",
      "======================================================================\n",
      " MEDS_ID  MEDS_ANNUAL_MEDIAN_ROW  YEAR  WaterLevel_m  WaterLevelElev_masl      Title Location      Lat     Lon tile_id   year            location  latitude  longitude   tile  mean_ET_mm_yr  buffer_radius_m\n",
      "      15                     507  2000      85.22369                  NaN MexicoAguascaliente 22.19816 -102.31  h08v06 2000.0 MexicoAguascaliente  22.19816    -102.31 h08v06     240.623062           1000.0\n",
      "      15                     508  2001      89.14079                  NaN MexicoAguascaliente 22.19816 -102.31  h08v06 2001.0 MexicoAguascaliente  22.19816    -102.31 h08v06     269.746155           1000.0\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "ET timeseries: /capstone/aridgw/data/et_timeseries_aguascaliente_test.csv\n",
      "Merged data: /capstone/aridgw/data/et_gw_merged_aguascaliente_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Use CSV file with corresponding tile IDs for each site to extract ET timeseries\n",
    "\n",
    "def extract_et_timeseries_single_site():\n",
    "    \"\"\"Extract annual ET timeseries for a single site using existing CSV\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"Extracting ET timeseries for: {SITE_NAME}\")\n",
    "    print(f\"Years: {START_YEAR}-{END_YEAR}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # STEP 1: Load site info from existing CSV\n",
    "\n",
    "    print(\"\\n STEP 1: Loading site information from CSV\")\n",
    "    \n",
    "    df_sites = pd.read_csv(sites_csv)\n",
    "    \n",
    "    # Filter to just this site\n",
    "    site_data = df_sites[df_sites['Title Location'] == SITE_NAME].iloc[0]\n",
    "    \n",
    "    site_lat = site_data['Lat']\n",
    "    site_lon = site_data['Lon']\n",
    "    tile_id = site_data['tile_id']\n",
    "    \n",
    "    print(f\"âœ“ Location: {SITE_NAME}\")\n",
    "    print(f\"âœ“ Coordinates: ({site_lat:.6f}, {site_lon:.6f})\")\n",
    "    print(f\"âœ“ MODIS Tile: {tile_id}\")\n",
    "    \n",
    "    # Extract h and v from tile_id (e.g., \"h08v05\" -> h=8, v=5)\n",
    "    h = int(tile_id[1:3])\n",
    "    v = int(tile_id[4:6])\n",
    "    \n",
    "    # STEP 2: Create buffer (One at time per site)\n",
    "\n",
    "    print(f\"\\n STEP 2: Creating {BUFFER_RADIUS}m buffer\")\n",
    "    \n",
    "    modis_crs = CRS.from_proj4(\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\")\n",
    "    circle_geom = create_circle_buffer(site_lat, site_lon, BUFFER_RADIUS, modis_crs)\n",
    "    print(f\"âœ“ Buffer created\")\n",
    "    \n",
    "    # STEP 3: Find and filter MODIS files according to tile and year range\n",
    "\n",
    "    print(f\"\\n STEP 3: Finding MODIS files for tile {tile_id}\")\n",
    "    \n",
    "    hdf_files = glob.glob(os.path.join(modis_data_dir, \"*.hdf\")) # Creates variable containing all .hdf files in modis_data_dir\n",
    "    print(f\"âœ“ Found {len(hdf_files)} total MODIS files\")\n",
    "    \n",
    "    # Parse and filter files for this tile and year range\n",
    "    file_dict = {}  # year -> filepath\n",
    "    for hdf_file in hdf_files: # Looks through all .hdf files in modis_data_dir\n",
    "        info = parse_modis_filename(os.path.basename(hdf_file)) # Parses filename to extract time and tile info\n",
    "        if info and info['tile'] == tile_id and START_YEAR <= info['year'] <= END_YEAR: # Filters files for specified tile and year range\n",
    "            file_dict[info['year']] = {'filepath': hdf_file, 'h': info['h'], 'v': info['v']} # Stores filtered files in dictionary with year as key\n",
    "    \n",
    "    print(f\"âœ“ Filtered to {len(file_dict)} files for {tile_id} ({START_YEAR}-{END_YEAR})\")\n",
    "    \n",
    "    if len(file_dict) == 0: # If no files found for specified tile and year range\n",
    "        print(f\"\\n WARNING: No files found for tile {tile_id} in year range\")\n",
    "        print(\"Available tiles in directory:\")\n",
    "        for hdf_file in hdf_files[:5]:  # Show first 5 as examples\n",
    "            info = parse_modis_filename(os.path.basename(hdf_file))\n",
    "            if info: \n",
    "                print(f\"  - {info['tile']} (year {info['year']})\")\n",
    "        return None, None\n",
    "    \n",
    "    # STEP 4: Extract ET for each year\n",
    "\n",
    "    print(f\"\\n STEP 4: Extracting ET values\") \n",
    "    print(f\"\\n{'Year':<8} {'Mean ET (mm/yr)':<20} {'Status'}\")\n",
    "    print(\"-\" * 50) \n",
    "    \n",
    "    results = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1): # Loops through each year in specified range\n",
    "        if year in file_dict: \n",
    "            file_info = file_dict[year]\n",
    "            mean_et = extract_et_from_buffer(\n",
    "                file_info['filepath'],\n",
    "                circle_geom,\n",
    "                file_info['h'],\n",
    "                file_info['v']\n",
    "            )\n",
    "            \n",
    "            status = \"âœ“\" if not np.isnan(mean_et) else \"NO DATA\"\n",
    "            et_display = f\"{mean_et:.2f}\" if not np.isnan(mean_et) else \"NaN\"\n",
    "            print(f\"{year:<8} {et_display:<20} {status}\")\n",
    "            \n",
    "            results.append({ # Appends results to list\n",
    "                'year': year,\n",
    "                'location': SITE_NAME,\n",
    "                'latitude': site_lat,\n",
    "                'longitude': site_lon,\n",
    "                'tile': tile_id,\n",
    "                'mean_ET_mm_yr': mean_et,\n",
    "                'buffer_radius_m': BUFFER_RADIUS\n",
    "            })\n",
    "        else:\n",
    "            print(f\"{year:<8} {'---':<20} FILE MISSING\")\n",
    "            results.append({\n",
    "                'year': year,\n",
    "                'location': SITE_NAME,\n",
    "                'latitude': site_lat,\n",
    "                'longitude': site_lon,\n",
    "                'tile': tile_id,\n",
    "                'mean_ET_mm_yr': np.nan,\n",
    "                'buffer_radius_m': BUFFER_RADIUS\n",
    "            })\n",
    "    \n",
    "    # STEP 5: Save ET results\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 5: Saving ET results\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_et = pd.DataFrame(results)\n",
    "    df_et = df_et.sort_values('year')\n",
    "    df_et.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"âœ“ ET data saved to: {output_csv}\")\n",
    "    print(f\"\\n ET Statistics:\")\n",
    "    print(f\"  Years with data: {df_et['mean_ET_mm_yr'].notna().sum()} / {len(df_et)}\")\n",
    "    \n",
    "    if df_et['mean_ET_mm_yr'].notna().sum() > 0:\n",
    "        print(f\"  Mean ET: {df_et['mean_ET_mm_yr'].mean():.2f} mm/yr\")\n",
    "        print(f\"  Min ET: {df_et['mean_ET_mm_yr'].min():.2f} mm/yr\")\n",
    "        print(f\"  Max ET: {df_et['mean_ET_mm_yr'].max():.2f} mm/yr\")\n",
    "        print(f\"  Std Dev: {df_et['mean_ET_mm_yr'].std():.2f} mm/yr\")\n",
    "    \n",
    "    # STEP 6: JOIN with groundwater data\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 6: Joining ET data with groundwater data\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load the full groundwater dataset\n",
    "    df_gw = pd.read_csv(sites_csv)\n",
    "    \n",
    "    # Filter to only this site\n",
    "    df_gw_site = df_gw[df_gw['Title Location'] == SITE_NAME].copy()\n",
    "    \n",
    "    print(f\"âœ“ Loaded {len(df_gw_site)} groundwater records for {SITE_NAME}\")\n",
    "    \n",
    "    # Perform the join\n",
    "    # Join on: location (from ET) = Title Location (from GW) AND year (ET) = YEAR (GW)\n",
    "    df_merged_all_years = pd.merge(\n",
    "        df_gw_site,\n",
    "        df_et,\n",
    "        left_on=['Title Location', 'YEAR'],\n",
    "        right_on=['location', 'year'],\n",
    "        how='left'  # Keep all groundwater records, add ET where available\n",
    "    )\n",
    "    # Filter to specified year range\n",
    "    print(f\"\\n Filtering to years {START_YEAR}-{END_YEAR}...\")\n",
    "\n",
    "    df_merged = df_merged_all_years[ # Filters merged dataframe to specified year range\n",
    "    (df_merged_all_years['YEAR'] >= START_YEAR) & \n",
    "    (df_merged_all_years['YEAR'] <= END_YEAR)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"âœ“ Merged dataset has {len(df_merged)} rows\")\n",
    "    print(f\"  Rows with ET data: {df_merged['mean_ET_mm_yr'].notna().sum()}\")\n",
    "    print(f\"  Rows without ET data: {df_merged['mean_ET_mm_yr'].isna().sum()}\")\n",
    "    \n",
    "    # Save merged dataset\n",
    "    df_merged.to_csv(merged_output_csv, index=False)\n",
    "    print(f\"âœ“ Merged data saved to: {merged_output_csv}\")\n",
    "    \n",
    "    # Show column comparison for verification\n",
    "    print(\"\\nðŸ“‹ Column verification (duplicate columns help verify alignment):\")\n",
    "    verification_cols = ['Title Location', 'location', 'YEAR', 'year', \n",
    "                        'Lat', 'latitude', 'Lon', 'longitude', \n",
    "                        'tile_id', 'tile']\n",
    "    available_cols = [col for col in verification_cols if col in df_merged.columns]\n",
    "    if available_cols:\n",
    "        print(df_merged[available_cols].head(5).to_string(index=False))\n",
    "    \n",
    "    return df_et, df_merged\n",
    "\n",
    "# RUN\n",
    "if __name__ == \"__main__\":\n",
    "    df_et, df_merged = extract_et_timeseries_single_site()\n",
    "    \n",
    "    if df_et is not None and df_merged is not None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ET OUTPUT PREVIEW\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_et.head(10).to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MERGED OUTPUT PREVIEW\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_merged.head(10).to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROCESSING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"ET timeseries: {output_csv}\")\n",
    "        print(f\"Merged data: {merged_output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AridGW-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
