{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46562c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Extracting ET timeseries for: Nevada (Amargosa)\n",
      "Years: 2000-2022\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ STEP 1: Loading site information from CSV\n",
      "âœ“ Location: Nevada (Amargosa)\n",
      "âœ“ Coordinates: (36.556340, -116.496000)\n",
      "âœ“ MODIS Tile: h08v05\n",
      "\n",
      "ðŸ”µ STEP 2: Creating 1000m buffer\n",
      "âœ“ Buffer created\n",
      "\n",
      "ðŸ“ STEP 3: Finding MODIS files for tile h08v05\n",
      "âœ“ Found 7139 total MODIS files\n",
      "âœ“ Filtered to 23 files for h08v05 (2000-2022)\n",
      "\n",
      "ðŸŒ STEP 4: Extracting ET values\n",
      "\n",
      "Year     Mean ET (mm/yr)      Status\n",
      "--------------------------------------------------\n",
      "2000     62.60                âœ“\n",
      "2001     72.81                âœ“\n",
      "2002     44.35                âœ“\n",
      "2003     68.05                âœ“\n",
      "2004     89.48                âœ“\n",
      "2005     104.47               âœ“\n",
      "2006     55.08                âœ“\n",
      "2007     47.01                âœ“\n",
      "2008     65.54                âœ“\n",
      "2009     57.58                âœ“\n",
      "2010     87.29                âœ“\n",
      "2011     68.50                âœ“\n",
      "2012     50.65                âœ“\n",
      "2013     56.54                âœ“\n",
      "2014     49.44                âœ“\n",
      "2015     54.70                âœ“\n",
      "2016     64.38                âœ“\n",
      "2017     55.35                âœ“\n",
      "2018     45.20                âœ“\n",
      "2019     85.66                âœ“\n",
      "2020     57.83                âœ“\n",
      "2021     50.76                âœ“\n",
      "2022     52.47                âœ“\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š STEP 5: Saving ET results\n",
      "======================================================================\n",
      "âœ“ ET data saved to: /capstone/aridgw/data/et_timeseries_amargosa.csv\n",
      "\n",
      "ðŸ“ˆ ET Statistics:\n",
      "  Years with data: 23 / 23\n",
      "  Mean ET: 62.86 mm/yr\n",
      "  Min ET: 44.35 mm/yr\n",
      "  Max ET: 104.47 mm/yr\n",
      "  Std Dev: 15.80 mm/yr\n",
      "\n",
      "======================================================================\n",
      "ðŸ”— STEP 6: Joining ET data with groundwater data\n",
      "======================================================================\n",
      "âœ“ Loaded 65 groundwater records for Nevada (Amargosa)\n",
      "\n",
      "ðŸ” Filtering to years 2000-2022...\n",
      "âœ“ Merged dataset has 23 rows\n",
      "  Rows with ET data: 23\n",
      "  Rows without ET data: 0\n",
      "âœ“ Merged data saved to: /capstone/aridgw/data/et_gw_merged_amargosa.csv\n",
      "\n",
      "ðŸ“‹ Column verification (duplicate columns help verify alignment):\n",
      "   Title Location          location  YEAR   year      Lat  latitude      Lon  longitude tile_id   tile\n",
      "Nevada (Amargosa) Nevada (Amargosa)  2000 2000.0 36.55634  36.55634 -116.496   -116.496  h08v05 h08v05\n",
      "Nevada (Amargosa) Nevada (Amargosa)  2001 2001.0 36.55634  36.55634 -116.496   -116.496  h08v05 h08v05\n",
      "Nevada (Amargosa) Nevada (Amargosa)  2002 2002.0 36.55634  36.55634 -116.496   -116.496  h08v05 h08v05\n",
      "Nevada (Amargosa) Nevada (Amargosa)  2003 2003.0 36.55634  36.55634 -116.496   -116.496  h08v05 h08v05\n",
      "Nevada (Amargosa) Nevada (Amargosa)  2004 2004.0 36.55634  36.55634 -116.496   -116.496  h08v05 h08v05\n",
      "\n",
      "======================================================================\n",
      "ðŸ“‹ ET OUTPUT PREVIEW\n",
      "======================================================================\n",
      " year          location  latitude  longitude   tile  mean_ET_mm_yr  buffer_radius_m\n",
      " 2000 Nevada (Amargosa)  36.55634   -116.496 h08v05      62.599998             1000\n",
      " 2001 Nevada (Amargosa)  36.55634   -116.496 h08v05      72.812500             1000\n",
      " 2002 Nevada (Amargosa)  36.55634   -116.496 h08v05      44.349998             1000\n",
      " 2003 Nevada (Amargosa)  36.55634   -116.496 h08v05      68.050003             1000\n",
      " 2004 Nevada (Amargosa)  36.55634   -116.496 h08v05      89.475006             1000\n",
      " 2005 Nevada (Amargosa)  36.55634   -116.496 h08v05     104.474998             1000\n",
      " 2006 Nevada (Amargosa)  36.55634   -116.496 h08v05      55.075001             1000\n",
      " 2007 Nevada (Amargosa)  36.55634   -116.496 h08v05      47.012497             1000\n",
      " 2008 Nevada (Amargosa)  36.55634   -116.496 h08v05      65.537506             1000\n",
      " 2009 Nevada (Amargosa)  36.55634   -116.496 h08v05      57.575001             1000\n",
      "\n",
      "======================================================================\n",
      "ðŸ“‹ MERGED OUTPUT PREVIEW\n",
      "======================================================================\n",
      " MEDS_ID  MEDS_ANNUAL_MEDIAN_ROW  YEAR  WaterLevel_m  WaterLevelElev_masl    Title Location      Lat      Lon tile_id   year          location  latitude  longitude   tile  mean_ET_mm_yr  buffer_radius_m\n",
      "       7                     258  2000     39.166800                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2000.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      62.599998           1000.0\n",
      "       7                     259  2001     39.157656                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2001.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      72.812500           1000.0\n",
      "       7                     260  2002     39.544752                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2002.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      44.349998           1000.0\n",
      "       7                     261  2003     40.465248                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2003.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      68.050003           1000.0\n",
      "       7                     262  2004     41.100756                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2004.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      89.475006           1000.0\n",
      "       7                     263  2005     41.611296                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2005.0 Nevada (Amargosa)  36.55634   -116.496 h08v05     104.474998           1000.0\n",
      "       7                     264  2006     42.150792                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2006.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      55.075001           1000.0\n",
      "       7                     265  2007     42.972228                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2007.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      47.012497           1000.0\n",
      "       7                     266  2008     43.586400                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2008.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      65.537506           1000.0\n",
      "       7                     267  2009     43.781472                  NaN Nevada (Amargosa) 36.55634 -116.496  h08v05 2009.0 Nevada (Amargosa)  36.55634   -116.496 h08v05      57.575001           1000.0\n",
      "\n",
      "======================================================================\n",
      "âœ… PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "ET timeseries: /capstone/aridgw/data/et_timeseries_amargosa.csv\n",
      "Merged data: /capstone/aridgw/data/et_gw_merged_amargosa.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyhdf.SD import SD, SDC\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import from_origin\n",
    "from pyproj import CRS\n",
    "import re\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - EDIT THESE\n",
    "# ============================================================================\n",
    "\n",
    "# Single site to process\n",
    "SITE_NAME = \"Nevada (Amargosa)\"\n",
    "\n",
    "# Year range\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2022\n",
    "\n",
    "# Paths\n",
    "sites_csv = \"/capstone/aridgw/data/2025_09_21_annual_median_groundwater_levels_16sites_tile_id.csv\"\n",
    "modis_data_dir = \"/capstone/aridgw/data/modis_data/\"\n",
    "output_csv = \"/capstone/aridgw/data/et_timeseries_amargosa.csv\"\n",
    "merged_output_csv = \"/capstone/aridgw/data/et_gw_merged_amargosa.csv\"  # NEW: merged output\n",
    "\n",
    "# Buffer radius in meters\n",
    "BUFFER_RADIUS = 1000  # 1 km\n",
    "\n",
    "# MODIS constants\n",
    "TILE_SIZE = 1111950.0\n",
    "X_MIN = -20015109.354\n",
    "Y_MAX = 10007554.677\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def parse_modis_filename(filename):\n",
    "    \"\"\"Extract year, tile, h, v from MODIS filename\"\"\"\n",
    "    pattern = r'MOD16A3GF\\.A(\\d{4})\\d{3}\\.h(\\d{2})v(\\d{2})\\.\\d{3}\\.\\d+\\.hdf'\n",
    "    match = re.search(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        return {\n",
    "            'year': int(match.group(1)),\n",
    "            'tile': f\"h{match.group(2)}v{match.group(3)}\",\n",
    "            'h': int(match.group(2)),\n",
    "            'v': int(match.group(3))\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def create_circle_buffer(center_lat, center_lon, radius_meters, target_crs):\n",
    "    \"\"\"Create circular buffer around point\"\"\"\n",
    "    point = gpd.GeoSeries([Point(center_lon, center_lat)], crs=\"EPSG:4326\")\n",
    "    point_projected = point.to_crs(epsg=3857)\n",
    "    circle = point_projected.buffer(radius_meters)\n",
    "    circle_target = circle.to_crs(target_crs)\n",
    "    return circle_target\n",
    "\n",
    "def extract_et_from_buffer(hdf_file, circle_geom, h, v):\n",
    "    \"\"\"Extract mean ET from buffer\"\"\"\n",
    "    try:\n",
    "        # Open HDF\n",
    "        hdf = SD(hdf_file, SDC.READ)\n",
    "        et_dataset = hdf.select('ET_500m')\n",
    "        scale_factor = et_dataset.scale_factor\n",
    "        fill_value = et_dataset.attributes()['_FillValue']\n",
    "        \n",
    "        # Read and clean data\n",
    "        et_data_raw = et_dataset[:].astype(float)\n",
    "        et_data_raw[et_data_raw == fill_value] = np.nan\n",
    "        et_data_raw[et_data_raw > 65500] = np.nan\n",
    "        et_data = et_data_raw * scale_factor\n",
    "        \n",
    "        # Setup geotransform\n",
    "        PIXELS = et_data.shape[0]\n",
    "        RES = TILE_SIZE / PIXELS\n",
    "        x_ul = X_MIN + h * TILE_SIZE\n",
    "        y_ul = Y_MAX - v * TILE_SIZE\n",
    "        transform = from_origin(x_ul, y_ul, RES, RES)\n",
    "        modis_crs = CRS.from_proj4(\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\")\n",
    "        \n",
    "        # Create profile and clip\n",
    "        profile = {\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": et_data.shape[0],\n",
    "            \"width\": et_data.shape[1],\n",
    "            \"count\": 1,\n",
    "            \"dtype\": \"float32\",\n",
    "            \"crs\": modis_crs,\n",
    "            \"transform\": transform,\n",
    "            \"nodata\": np.nan\n",
    "        }\n",
    "        \n",
    "        with MemoryFile() as memfile:\n",
    "            with memfile.open(**profile) as dataset:\n",
    "                dataset.write(et_data.astype(\"float32\"), 1)\n",
    "                clipped, _ = mask(dataset, circle_geom.geometry, crop=True)\n",
    "        \n",
    "        # Calculate mean\n",
    "        clipped_valid = clipped[0][~np.isnan(clipped[0])]\n",
    "        mean_et = clipped_valid.mean() if len(clipped_valid) > 0 else np.nan\n",
    "        \n",
    "        hdf.end()\n",
    "        return mean_et\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def extract_et_timeseries_single_site():\n",
    "    \"\"\"Extract annual ET timeseries for a single site using existing CSV\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"Extracting ET timeseries for: {SITE_NAME}\")\n",
    "    print(f\"Years: {START_YEAR}-{END_YEAR}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load site info from existing CSV\n",
    "    # ========================================================================\n",
    "    print(\"\\nðŸ“‹ STEP 1: Loading site information from CSV\")\n",
    "    \n",
    "    df_sites = pd.read_csv(sites_csv)\n",
    "    \n",
    "    # Filter to just this site\n",
    "    site_data = df_sites[df_sites['Title Location'] == SITE_NAME].iloc[0]\n",
    "    \n",
    "    site_lat = site_data['Lat']\n",
    "    site_lon = site_data['Lon']\n",
    "    tile_id = site_data['tile_id']\n",
    "    \n",
    "    print(f\"âœ“ Location: {SITE_NAME}\")\n",
    "    print(f\"âœ“ Coordinates: ({site_lat:.6f}, {site_lon:.6f})\")\n",
    "    print(f\"âœ“ MODIS Tile: {tile_id}\")\n",
    "    \n",
    "    # Extract h and v from tile_id (e.g., \"h08v05\" -> h=8, v=5)\n",
    "    h = int(tile_id[1:3])\n",
    "    v = int(tile_id[4:6])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Create buffer (only once)\n",
    "    # ========================================================================\n",
    "    print(f\"\\nðŸ”µ STEP 2: Creating {BUFFER_RADIUS}m buffer\")\n",
    "    \n",
    "    modis_crs = CRS.from_proj4(\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\")\n",
    "    circle_geom = create_circle_buffer(site_lat, site_lon, BUFFER_RADIUS, modis_crs)\n",
    "    print(f\"âœ“ Buffer created\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Find and filter MODIS files\n",
    "    # ========================================================================\n",
    "    print(f\"\\nðŸ“ STEP 3: Finding MODIS files for tile {tile_id}\")\n",
    "    \n",
    "    hdf_files = glob.glob(os.path.join(modis_data_dir, \"*.hdf\"))\n",
    "    print(f\"âœ“ Found {len(hdf_files)} total MODIS files\")\n",
    "    \n",
    "    # Parse and filter files for this tile and year range\n",
    "    file_dict = {}  # year -> filepath\n",
    "    for hdf_file in hdf_files:\n",
    "        info = parse_modis_filename(os.path.basename(hdf_file))\n",
    "        if info and info['tile'] == tile_id and START_YEAR <= info['year'] <= END_YEAR:\n",
    "            file_dict[info['year']] = {'filepath': hdf_file, 'h': info['h'], 'v': info['v']}\n",
    "    \n",
    "    print(f\"âœ“ Filtered to {len(file_dict)} files for {tile_id} ({START_YEAR}-{END_YEAR})\")\n",
    "    \n",
    "    if len(file_dict) == 0:\n",
    "        print(f\"\\nâš  WARNING: No files found for tile {tile_id} in year range\")\n",
    "        print(\"Available tiles in directory:\")\n",
    "        for hdf_file in hdf_files[:5]:  # Show first 5 as examples\n",
    "            info = parse_modis_filename(os.path.basename(hdf_file))\n",
    "            if info:\n",
    "                print(f\"  - {info['tile']} (year {info['year']})\")\n",
    "        return None, None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: Extract ET for each year\n",
    "    # ========================================================================\n",
    "    print(f\"\\nðŸŒ STEP 4: Extracting ET values\")\n",
    "    print(f\"\\n{'Year':<8} {'Mean ET (mm/yr)':<20} {'Status'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        if year in file_dict:\n",
    "            file_info = file_dict[year]\n",
    "            mean_et = extract_et_from_buffer(\n",
    "                file_info['filepath'],\n",
    "                circle_geom,\n",
    "                file_info['h'],\n",
    "                file_info['v']\n",
    "            )\n",
    "            \n",
    "            status = \"âœ“\" if not np.isnan(mean_et) else \"NO DATA\"\n",
    "            et_display = f\"{mean_et:.2f}\" if not np.isnan(mean_et) else \"NaN\"\n",
    "            print(f\"{year:<8} {et_display:<20} {status}\")\n",
    "            \n",
    "            results.append({\n",
    "                'year': year,\n",
    "                'location': SITE_NAME,\n",
    "                'latitude': site_lat,\n",
    "                'longitude': site_lon,\n",
    "                'tile': tile_id,\n",
    "                'mean_ET_mm_yr': mean_et,\n",
    "                'buffer_radius_m': BUFFER_RADIUS\n",
    "            })\n",
    "        else:\n",
    "            print(f\"{year:<8} {'---':<20} FILE MISSING\")\n",
    "            results.append({\n",
    "                'year': year,\n",
    "                'location': SITE_NAME,\n",
    "                'latitude': site_lat,\n",
    "                'longitude': site_lon,\n",
    "                'tile': tile_id,\n",
    "                'mean_ET_mm_yr': np.nan,\n",
    "                'buffer_radius_m': BUFFER_RADIUS\n",
    "            })\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Save ET results\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“Š STEP 5: Saving ET results\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_et = pd.DataFrame(results)\n",
    "    df_et = df_et.sort_values('year')\n",
    "    df_et.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"âœ“ ET data saved to: {output_csv}\")\n",
    "    print(f\"\\nðŸ“ˆ ET Statistics:\")\n",
    "    print(f\"  Years with data: {df_et['mean_ET_mm_yr'].notna().sum()} / {len(df_et)}\")\n",
    "    \n",
    "    if df_et['mean_ET_mm_yr'].notna().sum() > 0:\n",
    "        print(f\"  Mean ET: {df_et['mean_ET_mm_yr'].mean():.2f} mm/yr\")\n",
    "        print(f\"  Min ET: {df_et['mean_ET_mm_yr'].min():.2f} mm/yr\")\n",
    "        print(f\"  Max ET: {df_et['mean_ET_mm_yr'].max():.2f} mm/yr\")\n",
    "        print(f\"  Std Dev: {df_et['mean_ET_mm_yr'].std():.2f} mm/yr\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 6: JOIN with groundwater data\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ”— STEP 6: Joining ET data with groundwater data\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load the full groundwater dataset\n",
    "    df_gw = pd.read_csv(sites_csv)\n",
    "    \n",
    "    # Filter to only this site\n",
    "    df_gw_site = df_gw[df_gw['Title Location'] == SITE_NAME].copy()\n",
    "    \n",
    "    print(f\"âœ“ Loaded {len(df_gw_site)} groundwater records for {SITE_NAME}\")\n",
    "    \n",
    "    # Perform the join\n",
    "    # Join on: location (from ET) = Title Location (from GW) AND year (ET) = YEAR (GW)\n",
    "    df_merged_all_years = pd.merge(\n",
    "        df_gw_site,\n",
    "        df_et,\n",
    "        left_on=['Title Location', 'YEAR'],\n",
    "        right_on=['location', 'year'],\n",
    "        how='left'  # Keep all groundwater records, add ET where available\n",
    "    )\n",
    "    # Filter to specified year range\n",
    "    print(f\"\\nðŸ” Filtering to years {START_YEAR}-{END_YEAR}...\")\n",
    "\n",
    "    df_merged = df_merged_all_years[\n",
    "    (df_merged_all_years['YEAR'] >= START_YEAR) & \n",
    "    (df_merged_all_years['YEAR'] <= END_YEAR)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"âœ“ Merged dataset has {len(df_merged)} rows\")\n",
    "    print(f\"  Rows with ET data: {df_merged['mean_ET_mm_yr'].notna().sum()}\")\n",
    "    print(f\"  Rows without ET data: {df_merged['mean_ET_mm_yr'].isna().sum()}\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Save merged dataset\n",
    "    df_merged.to_csv(merged_output_csv, index=False)\n",
    "    print(f\"âœ“ Merged data saved to: {merged_output_csv}\")\n",
    "    \n",
    "    # Show column comparison for verification\n",
    "    print(\"\\nðŸ“‹ Column verification (duplicate columns help verify alignment):\")\n",
    "    verification_cols = ['Title Location', 'location', 'YEAR', 'year', \n",
    "                        'Lat', 'latitude', 'Lon', 'longitude', \n",
    "                        'tile_id', 'tile']\n",
    "    available_cols = [col for col in verification_cols if col in df_merged.columns]\n",
    "    if available_cols:\n",
    "        print(df_merged[available_cols].head(5).to_string(index=False))\n",
    "    \n",
    "    return df_et, df_merged\n",
    "\n",
    "# ============================================================================\n",
    "# RUN\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_et, df_merged = extract_et_timeseries_single_site()\n",
    "    \n",
    "    if df_et is not None and df_merged is not None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“‹ ET OUTPUT PREVIEW\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_et.head(10).to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“‹ MERGED OUTPUT PREVIEW\")\n",
    "        print(\"=\"*70)\n",
    "        print(df_merged.head(10).to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"âœ… PROCESSING COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"ET timeseries: {output_csv}\")\n",
    "        print(f\"Merged data: {merged_output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AridGW-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
